---
title: "Lesson 13: Bootstrap and permutations"
author: "Copyright 2025 Psychology Department. Hebrew University of Jerusalem. All rights reserved"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: false
  

description: >
  <div style='direction: rtl;'>
  בלומדה זאת נלמד על ייצור התפלגות משוערת באמצעות בוטסטרפ ועל ביצוע מבחנים בשיטה אפרמטרית באמצעות מבחן פרמוטציות
  </div>
runtime: shiny_prerendered
---

<style>
h1, h2, h3, h4, h5, h6 {
  direction: rtl;
}
p {
  direction: rtl;
}
</style>


```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(Rcourse)
library(tidyr)
library(ggplot2)
library(dplyr)
library(ggcheck)

# simulate data 
# 2 sample t test
set.seed(5)
n=300
salary_with <- rnorm(n , mean=11000, sd=2000)
salary_without <- rnorm(n , mean=9000, sd=2000)
# add some extreams to justify median
salary_with[sample(1:300, size=15)]= sample(2000:7000, size=15)

salary_without[sample(1:300, size=15)]= sample(25000:40000, size=15)
df = data.frame(programming=salary_with, no_programming=salary_without)

salary_df <- df %>% pivot_longer(cols = everything(), names_to = "group", values_to = "salary")
salary_df$gender <- rbinom(nrow(salary_df), 1, 0.5)
salary_df$gender = as.factor(salary_df$gender)
levels(salary_df$gender) = c("Male", "Female")

# coin sample
coin_sample <- rbinom(30, 10, 0.5)/10

tutorial_options()
knitr::opts_chunk$set(error = TRUE)
#########
#  function
exercises_df = data.frame(exercises = c("sample_q", "boot_loop_ex", "boot_n10_q", "boot_n10_q1_q", "quantile_2samp_ex", "perm_2samp_ex", "paired_perm_q", "perm_dep_loop_ex", "n_perm_q", "one_samp_perm_ex",
 "final_q1", "final_q2", "final_q2_2", "final_q3_1", "final_q3_2"),
                          hebrew = c("שאלת דגימה", "תרגיל: לולאת הבוטסארפ", "שאלה: אחוזונים בבוטסטרפ 1", "שאלה: אחוזונים בבוטסטרפ 2", "תרגיל: אחוזונים בפרמוטציות", "תרגיל: פרמוטציות לשני מדגמים ", "שאלה: פרמוטציות למדגמים מזווגים", "תרגיל: פרמוטציות למדגמים מזווגים", "שאלה:  אמינות הפרמוטציות", "תרגיל: פרמוטציות לערך ייחוס",
 "שאלה: תרגיל מסכם 1", "שאלה: תרגיל מסכם 2", "שאלה: תרגיל מסכם 3", "שאלה: תרגיל מסכם 4", "שאלה: תרגיל מסכם 5"))


check_hash_code   = function(hash){
    exercises = exercises_df$exercises
    response_table = learnrhash::decode_obj(hash)
    if (length(response_table)==0){return("Invalid hash code")}
    correct = response_table %>% filter(label %in% exercises, correct) %>% pull(label)
    incorrect = setdiff(exercises, correct)
    if (length(incorrect) == 0){return("Great work! Hash code is valid")}
    else{
      hebrew = exercises_df  %>% filter(exercises %in% incorrect) %>%pull(hebrew)
      print("The following exercises are missing or incorrect:")
      print(hebrew)
    }

} 
# hash checker


```
## מבחנים א-פרמטרים - מבוא

בשיעור זה אנחנו נלמד איך לבצע מבחנים סטטיסטיים שנקראים מבחנים א-פרמטרים.  
כלומר, המבחנים שלמדנו עד עכשיו הם מבחנים פרמטרים. אתם בטח שואלים למה אנחנו בכלל צריכים מבחנים שאינם פרמטריים?  
כמו שהבנתם עד עכשיו, יש מקרים בהם לא נוכל לבצע את המבחנים שלמדנו עליהם עד עכשיו, כאשר הנחות המבחן לא מתקיימות.  
במבחן t למשל אנחנו מניחים שהתפלגות האוכלוסיה היא נורמלית. נניח ודגמנו מדגם של משתנה כלשהו וגילינו שהנחת הנורמליות לא מתקיימת, לא נוכל לבצע מבחן t ולהסיק הסקות לגבי המדגם כך.
אבל בשיטות א-פרטריות נוכל עדיין לבצע בדיקת השערות.  
הנה כמה דוגמאות למקרים בהם נרצה לבצע מבחן א-פרמטרי:  
- ידוע כי המשתנה לא מתפלג נורמלית.  
- גודל המדגם קטן מידי.  
- לא ניתן להניח התפלגות דגימה נורמלית לסטטיסטי (למשל אם נרצה לבצע בדיקה של החציון או של אחוזון מסוים).  

חשוב להבהיר, שזה לא שהמבחנים הא-פרמטרים פחות טובים אלא פשוט לא נשענים על אותן הנחות. בגדול כאשר ההנחות מתקיימות ההחלטות של שני סוגי המבחנים אמורות לצאת דומות מאוד.

`שימוש באקראיות`  
בr יש לנו יכולת לבצע מגוון של תהליכים באופן אקראי. תיחשפו למגוון דוגמאות בלומדה זאת. אך יש גם דרך לשלוט באקראיות על ידי שורת הקוד:
`set.seed(n)`  
n מייצג כל מספר שתבחרו.  
כאשר נריץ את שורת קוד זאת ונבצע תהליך אקראי מסוים התוצאה שתתקבל תהיה זהה בכל פעם. כלומר, בלומדה השתמשנו בשורת קוד זאת כדי שנעבוד על אותם תהליכים שכבר הרצנו ואנחנו יודעים מה התקבל בהם בדיוק. 

## Bootstrap

 משמעות המונח בוטסטרפ לקוחה מהמשפט ל"משוך את עצמך באמצעות רצועות המגפיים שלך". כלומר, להצליח בתנאים בלתי אפשריים, לייצר יש מאין. 
 זה בדיוק מה שנעשה בשיעור הזה. יש לנו מדגם וסטטיסטי שמתאר אותו. אבל לא נוכל להניח התפלגות נורמלית של המשתנה ולכן לא נוכל להסתמך על התפלגויות ידועה ואנחנו נצטרך לייצר את ההתפלגות המלאה יש מאין.   
 באמצעות בוטסטרפ נוכל לדמות את ההתפלגות של המשתנה על סמך נתוני המדגם ללא צורך בהסתמכות על הנחות לגבי צורת ההתפלגות של המשתנה.
לצורך הסימולציה של התפלגות הבוטסטרפ נצטרך להשתמש בלולאות.  

נתחיל עם דוגמה פשוטה עם נתונים מדומים. אנחנו נרצה שהלולאה בעצם תחזור על עצמה ככמות האיטרציות הרצויה (למשל מינימום 1000, אבל במקרים רבים אולי נשאף ליותר חזרות). בכל חזרה של הלולאה נדגום מדגם חדש מתוך המדגם הקיים. שימו לב - הדגימה פה צריכה להיות עם החזרה. כך שיכול להיות שיווצר לנו מדגם שכולל רק תצפית אחת מתוך המדגם הרבה פעמים, מדגם שזהה למדגם המקורי והרבה מדגמים שמשלבים סט חלקי של תצפיות מתוך המדגם המקורי. לפני שנבנה את הלולאה בואו נראה איך נראית הדגימה עצמה, לשם כך נשתמש בפונקציה `sample`.   

תזכורת לגבי הארגומנטים (קלטים) שהפונקציה יכולה לקבל:  
`x` - וקטור המכיל נתונים מהם יש לבצע דגימה   
`size` - כמות התצפיות בכל דגימה (אם לא נכניס כלום הפונקציה תדמה מדגמים בעלי גודל זהה לx)   
`replace` - האם לבצע דגימה עם החזרה (TRUE) או בלי (FALSE)   
`prob` - מה ההסתברות של כל תצפית בנתונים המקוריים. אם לא נכניס כלום הפונקציה תניח שכל תצפית היא בסבירות שווה.   

```{r}
# נתחיל עם מדגם היפוטתי פשוט מאוד
original_data <- c(1,2,3,4,5)
# נחשב את ממוצע המדגם
original_mean <- mean(original_data)
# ונציג אותו - זה הממוצע של המדגם המקורי שלנו
original_mean

# כדי לדמות מדגמים אשר מסתמכים על המדגם המקורי נדגום ממנו
# נשתמש בדגימה עם החזרה
sampled_data <- sample(original_data, replace = TRUE)
# נצפה במדגם שקיבלנו
sampled_data
# נחשב את הממוצע גם עבורו
sampled_mean <- mean(sampled_data)
# נדפיס
sampled_mean
```

```{r sample_q, echo = FALSE}
question("מה היה קורה אם היינו משתמשים בדגימה בלי החזרה?",
         answer("ממוצע המדגם שדגמנו היה זהה למדגם המקורי בכל פעם שהיינו מריצים את הקוד", correct = TRUE,  message ="נכון. אם היינו רוצים לדגום מדגם חדש עם באותו הגודל של המדגם המקורי ללא החזרה היינו מקבלים מדגם שמכיל את כל התצפיות המקוריות אך לא בהכרח באותו הסדר. שימו לב זה יכול להיות שימושי בהמשך."),
         answer("המדגם המדומה היה תמיד זהה למדגם המקורים", message = " כמעט, אבל לא בדיוק. תהליך הדגמיה יכול לשנות את הסדר של הוקטור, זה לא ישפיע על הממוצע אבל זה יכול להשפיע על פעולות אחרות שאפשר לבצע עם וקטורים "),
         answer("הייתה מתקבלת שגיאה", message = "לא נכון, הפונקציה בהחלט מסוגלת לבצע דגימה כזאת, נסו ותראו."),
         answer("עדיין נוכל לקבל מדגמים מגוונים כמו בהדגמה אך עם הבדלים קטנים יותר בינהם.", message = "לא נכון, דגימה ללא החזרה הייתה גורמת לכך שהפונציה תמיד הייתה דוגמת 5 ערכים מתוך הוקטור המקורי אך לא היה ניתן לדגום  את אותו ערך פעמיים. לכן התוצאה הייתה תמיד וקטור שמכיל את כל הערכים המקוריים רק בסדר אחר.  "),
         allow_retry = TRUE
)
```

מעולה דימינו מדגם על בסיס הנתונים המקוריים, קיבלנו ממוצע אחר מהממוצע המקורים עבור הדגימה הזאת.  


### לולאת הבוטסטראפ
השלב הבא יהיה לחזור על התהליך 1000 פעמים, לפחות.  
מזל שלמדנו לולאות. בשיעורים הקודמים למדנו שכל חזרה על לולאה נקראית איטרציה, כדי לבצע מבחן בוטסטרפ נצטרך לבצע מספר רב של איטרציות אבל נתחיל מלהוסיף מעט חזרות, כדי שנוכל ממש לראות את התוצר של כל חזרה נתחיל עם 5 חזרות.  
בואו נוסיף את הלולאה:

```{r}
# נחזור לאותו המדגם עם הממוצע הידוע
original_data <- c(1,2,3,4,5)
original_mean <- mean(original_data)

# נקבע מה מספר החזרות
# נתחיל עם מספר קטן ונתקדם
n_iter = 5

# נפתח את הלולאה
# נשתמש פשוט בטווח של בין 1 למספר האיטרציות כדי לחזור התהליך
for (i in 1:n_iter){
  # כדי לדמות מדגמים אשר מסתמכים על המדגם המקורי נדגום ממנו
  # נשתמש בדגימה עם החזרה
  sampled_data <- sample(original_data, replace = TRUE)
  # נצפה במדגם שקיבלנו
  sampled_data
  # נחשב את הממוצע גם עבורו
  sampled_mean <- mean(sampled_data)
  # נדפיס
  print(sampled_mean)
}

```

הרצנו את הלולאה ועכשיו יכולנו לראות את הממוצע של 5 מדגמים שונים אקראיים שונים. אנחנו יכולים להתרשם מכך שיש תנודות בממוצע, לפעמים הוא מתחת לממוצע המקורי, לפעמים שווה לו ולפעמים מעליו.  
כמובן ש5 ערכים הם עדיין לא התפלגות ממש. לכן נצטרך להוסיף עוד חזרות כדי לדמות את התפלגות הממוצע. 
כדי שממש נוכל לראות את ההתפלגות אנחנו צריכים לשמור את הממוצעים של המדגמים המדומים בוקטור, ממוצעים אלה יהוו בעצם את התפלגות הדגימה המדומה של הממוצע.   

### שמירת והצגת התוצאות

עכשיו כשנתחיל לעבוד עם חזרות רבות יותר נצטרך לקחת בחשבון את `יעילות הריצה`. הביצוע של פעולה מספר רב יותר של פעמים יכולה להעמיס על המחשב. לכן נצטרך לקחת את זה בחשבון. למשל הדפסה של נתונים רבים בכל סיבוב של הלולאה תגרום לעומס ותאט את הפעילות. זה לא משפיע כמעט בכלל ב5 חזרות אבל ב10000 חזרות נרגיש את ההבדל. לכן נרצה לבחון את הקוד טוב טוב ולוודא שהריצה תהיה חלקה וכי אנחנו מדפיסים תוך כדי הלולאה רק את מה שמאוד הכרחי.  
כמו כן, ניקח בחשבון את היעילות בעת שמירת הנתונים.
ברמת העיקרון היינו יכולים ליצור וקטור ריק בתחילת הלולאה ולהוסיף לו ערך אחד בכל סיבוב. תהליך זה פחות יעיל חישובית, זה האמנם זניח כשמשתמשים ב5 איטרציות אבל ככל שנוסיף איטרציות תהיה תוספת משמעותית יותר של זמן הריצה. עדיף ליצור וקטור ריק שמכיל ערכים ככמות האיטרציות ולערוך ערך אחד כל פעם.  
לשם כך נשתמש בפונקציה `numeric()` אשר מקבלת את מספר הערכים הרצוי בוקטור ויוצרת וקטור מספרי המכיל אפסים.   
בואו נשלים את התהליך:

```{r}
set.seed(123)
# נחזור לאותו המדגם עם הממוצע הידוע
original_data <- c(1,2,3,4,5)
original_mean <- mean(original_data)

# נקבע מה מספר החזרות
# נתקדם למספר קצת יותר גדול
n_iter = 50
# ניצור את הוקטור שישמור את התוצאות
sampled_means <- numeric(n_iter)

# נפתח את הלולאה
# נשתמש פשוט בטווח של בין 1 למספר האיטרציות כדי לחזור התהליך
for (i in 1:n_iter){
  # דגימה
  sampled_data <- sample(original_data, replace = TRUE)
  # בכל איטרציה נשמור את הממוצע של המדגם המדומה
  sampled_means[i] <- mean(sampled_data)
}
# נדפיס את הממוצעים
sampled_means

# בעצם יהיה יותר קל להציג אותם כהיסטוגרמה 
# נשמור אותם בטבלה לטובת האיור
df <- data.frame(sampled_means=sampled_means)

#איור
hist_plot <- ggplot(df, aes(x=sampled_means))+geom_histogram(bins=5)

# נוסיף לההתפלגות החדשה את הממוצע המקורי. 
hist_plot + geom_vline(xintercept = original_mean, color ="red")
```

אנחנו יכולים לראות שממוצע המחקר המקורי נופל יחסית במרכז ההתפלגות והערך גם יחסית שכיח בהתפלגות המדומה. הערכים הפחות נפוצים הם ערכים סביב 1 ו5, שכן כדי לקבל מדגם שהממוצע שלו הוא 1 היה צריך לדגום במקרה את הערך 1 מתוך המדגם המקורי 5 פעמים (או את הערך 5 במקרה של ממוצע של 5). ההסתברות שמדגם כזה יתקבל היא יחסית נמוכה אבל אפשרית ולכן השכיחות של הממוצעים בשתי קצוות ההתפלגות נמוכה.

`תרגיל`  
בתיבת הקוד למטה נתונים לכם נתונים מדומים של מדגם. כתבו קוד שמחשב התפלגות בוטסטרפ לחציון המדגם. כתבו את הקוד כך שהלולאה תייצר לנו התפלגות על סמך 1000 חזרות. איירו את ההיסטוגרמה של התפלגות הבוטסטרפ של החציון בהשוואה לחציון המקורי במדגם המדומה. והדפיסו את הממוצע של התפלגות הבוטסטרפ.

הערה - הימנעו מלהדפיס משתנים תוך כדי הלולאה, זה יאט את זמן הריצה ויבצע המון הדפסות.

```{r boot_loop_ex, exercise=TRUE, exercise.eval = FALSE,exercise.reveal_solution=FALSE}
set.seed(123)
# נדמה נתונים מהתפלגות נורמלית
original_data <- rnorm(30 , mean=0, sd=2)
# חישוב החציון 
original_median <- 
  
# נקבע את הפרמטרים של לולאת הבוסטסטרפ
n_iter <-
# ניצור את הוקטור שישמור את התוצאות
sampled_medians <- 
  
# בצעו את הלולאה כאן
  
  
# בצעו את האיור
hist_plot <- 
  

# נדפיס את הממוצע 
round(mean(sampled_medians),2)
  

```

```{r boot_loop_ex-solution}
set.seed(123)
original_data <- rnorm(30 , mean=0, sd=2)
# חישוב החציון 
original_median <- median(original_data)
  
# נקבע את הפרמטרים של לולאת הבוסטסטרפ
n_iter <- 1000
# ניצור את הוקטור שישמור את התוצאות
sampled_medians <- numeric(n_iter)
  
# בצעו את הלולאה כאן
for (i in 1:n_iter){
  sampled_data <- sample(original_data, replace = TRUE)
  sampled_medians[i] <- median(sampled_data)
  
} 

df = data.frame(sampled_medians=sampled_medians)
  
# בצעו את האיור
hist_plot <- ggplot(df, aes(x=sampled_medians)) + geom_histogram(bins=10) + geom_vline(xintercept = original_median, color ="red")

hist_plot

round(mean(sampled_medians),2)
```

```{r boot_loop_ex-check}
grade_result(pass_if(~identical(.result, -0.23)),
  
    correct="כל הכבוד! הבוטסטרפ שלכם עבד מעולה!", 
  incorrect = "נסו שוב! זכרו להדפיס את הממוצע של התפלגות הבוטסטרפ"
)
```

### רווח סמך עם בוטסטרפ
עד כה הבנו איך לייצר את התפלגות הבוטסטרפ אבל עוד לא ממש למדנו איך להשתמש בה בפועל.  
הבוסטרפ בעצם מייצר לנו התפלגות של מדד מרכזי במשתנה, בעזרת ההתפלגות נוכל לחשב את רווח הסמך ולבחון למשל האם ממוצע המדגם שלנו שונה ממוצע המדגם תחת השערת האפס.  

בואו נראה דוגמאות:  

נתחיל עם דוגמה פשוטה שכן משתמשת בהתפלגות נורמלית ונבנה עליה.   
במקרה זה הסיבה שנבחר בחישוב הא-פרמטרי של רווח הסמך היא שנרצה להשתמש בחציון ולא בממוצע.  
נניח שדגמנו את השכר של מי שלמד תכנות במהלך התואר הראשון 5 שנים לאחר סיום התואר. המטרה הייתה לבחון איך לימודי תכנות השפיעו על השכר, השערת האפס היא שחציון השכר של מי שלמד תכנות כחלק מלימודי התואר תהיה זהה לשכר החציוני   במשק (9100). בואו נבחן את ההשערה.  

```{r}
set.seed(123)
salary_data <- rnorm(300 , mean=11000, sd=8000)
# חישוב החציון 
salary_median <- median(salary_data)
  
# נקבע את הפרמטרים של לולאת הבוסטסטרפ
n_iter <- 1000
# ניצור את הוקטור שישמור את התוצאות
sampled_medians <- numeric(n_iter)
  
# הלולאה 
for (i in 1:n_iter){
  sampled_data <- sample(salary_data, replace = TRUE)
  sampled_medians[i] <- median(sampled_data)
} 

# נחשב את רווח הסמך

# נקבע את רמת הבטחון
conf_level = 0.95

# נחשב את אלפא
alpha <- 1-conf_level

# נחשב הסף העליון והתחתון של רווח הסמך על סמך ההתפלגות 
lower <- quantile(sampled_medians, alpha / 2)
upper <- quantile(sampled_medians, 1 - alpha / 2)
# נציג
paste0("the bootstrapped CI is: ", round(lower), " - ", round(upper), " ILS")


# נרצה  להשוות את ההתפלגות לשכר החציוני
reference <- 9100

# נבדוק האם השכר החציוני במשק נמצא בתוך הרווח
if (lower > reference | upper< reference){
  print("חציון השכר הארצי נמצא מחוץ לרווח הסמך ברמת בטחון של 95%")
} else {
  print("ערך הייחוס נמצא בתוך רווח הסמך")
}
 
 
# עכשיו נציג את האיור
hist_plot<-ggplot(data.frame(sampled_medians = sampled_medians), aes(x = sampled_medians)) + geom_histogram(binwidth = 300) +
  geom_vline(xintercept = salary_median, color = "red", linetype = "dashed") +
  geom_vline(xintercept = c(lower, upper), color = "green") +
  geom_vline(xintercept = reference, color = "blue") +
  annotate("text", x = salary_median, y = 10, label = "Sample Median", color = "red") +
  annotate("text",x = lower, y = 10, label = "Lower CI", color = "green") +
  annotate("text",x = upper, y = 10, label = "Upper CI", color = "green") +
  annotate("text",x = reference, y = 200, label = "Reference", color = "blue") + xlab("Sampled Medians") + ylab("Frequency")

hist_plot


```

אם נתבונן יחד באיור נוכל לראות את ההתפלגות עצמה, יחד עם החציון המקורי, השכר החציוני במשק (כחול) וגבולות רווח הסמך (ירוק).  
אפשר לראות שהשכר החציוני במשק נמצא מחוץ לרווח הסמך.   
זוהי רק דוגמה בה היה לנו ערך ייחוס, אבל השימוש בבוטסטרפ יכול להיות גם תיאורי לגמרי.  

### האם זה באמת עובד?

משוכנעים שזה עובד?  
אם לא, בואו נראה הדגמה. נוכל לקחת התפלגות שאיננה נורמלית, לדמות אוכלוסיה שלמה. לאחר מכן נוכל לדגום מדגם בודד מתוך האוכלוסיה ולנסות לשחזר את התפלגות הדגימה שלה באמצעות בוטסטרפ. נדמה אוכלוסיה דו שכיחית, בה ערכים שקרובים ל0 לא נפוצים כל כך אבל ערכים סביב 3 ו -3 נפוצים במידה דומה.  
בואו נתחיל  

```{r}
set.seed(22)
# נדמה את האוכלוסיה באמצעות חיבור של שתי התפלגויות נורמליות
# נניח אוכלוסיה של 100000
n = 100000
dist = (c(rnorm(n/2, mean = -2, sd = 1), rnorm(n/2, mean = 3, sd = 1)))
# נשמור אותה בטבלה
dist_df <- data.frame(dist=dist)
# נציג איור של ההתפלגות
ggplot(dist_df, aes(x=dist)) + geom_histogram(bins =100)

# עכשיו ייצרנו פה מצב שיש לנו אוכלוסיה ידועה
# בואו נדגום ממנה מדגם 
# נדגום בלי החזרה כדי לדמות מדגם בו כל אחד יכול להשתתף עד פעם אחת
original_sample <- sample(dist, 30, replace = FALSE)
# נחשב את הממוצע
original_mean <- mean(original_sample)
print(original_mean)

# ועכשיו לבוטסטרפ
n_iter <- 10000
bootstrap_data <- numeric(n_iter)
# נבצע לולאה
for (i in 1:n_iter){
  # נדגום עם החזרה מדגמים מתוך המדגם 
  temp_sampled <- sample(original_sample, replace = TRUE)
  # נחשב את החציון לכל מדגם
  bootstrap_data[i] <- mean(temp_sampled)
} 

# נשמור את התפלגות הבוטסטרפ בטבלה
boot_dist_df <- data.frame(bootstrap_dist=bootstrap_data)

# נציג איור של ההתפלגות
ggplot(boot_dist_df, aes(x=bootstrap_dist)) + geom_histogram(bins =100)

# קיבלנו מתוך המדגם הבודד הערכה להתפלגות הדגימה של הממוצע מתוך האוכלוסיה 
# עכשיו נוכל להשוות אותה להתפלגות הדגימה התיאורטית
# על ידי דגימה של מספר רב של מדגמים מתוך ההתפלגות המקורית

# ניצור את הוקטור שישמור את התפלגות הדגימה
sampled_dist <- numeric(n_iter)
  
# נתחיל את הלולאה
for (i in 1:n_iter){
  # נדגום ללא החזרה מדגמים של 30 משתתפים
  sampled_data <- sample(dist, size=30, replace = FALSE)
  # נחשב את ממוצע לכל מדגם
  sampled_dist[i] <- mean(sampled_data)
} 
# נוסיף את התפלגות הדגימה האמיתית לטבלת הבוטסטרפ כדי להשוות בינהן
boot_dist_df$sample_dist <- sampled_dist
# נמיר לפורמט ארוך
long_df <- gather(boot_dist_df, key="Dist", value="Mean")
# נציג איור של ההתפלגות
ggplot(long_df, aes(x=Mean, col=Dist)) + geom_histogram(fill="white", alpha=0.5, position="identity", bins =100)

# בואו נשווה אותן לממוצע של ההתפלגות האמיתית
print(paste0("The difference between original distribution and bootstrapped mean is: ", mean(bootstrap_data)-mean(original_mean)))
print(paste0("The difference between original distribution and sample distribution means is: ", mean(sampled_dist)-mean(original_mean)))
# ואחת לשניה
print(paste0("The difference between distribution means is: ", mean(bootstrap_data)-mean(sampled_dist)))

```

קיבלנו תוצאה קצת מדהימה! ממדגם אחד שדגם 30 משתתפים מתוך האוכלוסיה כולה הצלחנו לשחזר באופן לא רע בכלל את התפלגות הדגימה של האוכלוסיה, כפי שחולצה מתוך האוכלוסיה. זאת למרות שאנחנו יודעים שהאוכלוסיה לא מתפלגת נורמלי. בתיבה מטה נמצאת גרסה מתומצתת של הקוד. עכשיו אתם יכולים להתנסות בעצמכם.  
בצעו שני שינויים בקוד:  
1. שנו את גודל הדגימה ל10 משתתפים והריצו את הקוד.  
2. שנו גם את המדד המרכזי למיקום הרבעון הראשון (אחוזון 25) והריצו שוב

```{r boo_samp_dist_ex, exercise=TRUE, exercise.eval = FALSE }
set.seed(22)
# האוכלוסיה (אין צורך לשנות)
n = 100000
dist = (c(rnorm(n/2, mean = -2, sd = 1), rnorm(n/2, mean = 3, sd = 1)))

# דגימת מדגם
# אפשר לשנות את גודל המדגם באמצעות עריכה המשתנה הזה
sample_size <- 30
original_sample <- sample(dist, sample_size, replace = FALSE)
# חישוב המדד המרכזי
original_est <- mean(original_sample)
print(original_est)

#  בוטסטרפ
n_iter <- 10000
bootstrap_data <- numeric(n_iter)
# נבצע לולאה
for (i in 1:n_iter){
  temp_sampled <- sample(original_sample, replace = TRUE)
  bootstrap_data[i] <- mean(temp_sampled)
} 

# נשמור את התפלגות הבוטסטרפ בטבלה
dist_df <- data.frame(bootstrap_dist=bootstrap_data)

# התפלגות הדגימה
sampled_dist <- numeric(n_iter)
  
# נתחיל את הלולאה
for (i in 1:n_iter){
  sampled_data <- sample(dist, size=sample_size, replace = FALSE)
  sampled_dist[i] <- mean(sampled_data)
} 
# ארגון בטבלה
dist_df$sample_dist <- sampled_dist
long_df <- gather(dist_df, key="Dist", value="Mean")

# איור המשווה בין שתי ההתפלגויות
ggplot(long_df, aes(x=Mean, col=Dist)) + geom_histogram(fill="white", alpha=0.5, position="identity", bins =100)

print(paste0("The difference between distribution means is: ", mean(bootstrap_data)-mean(sampled_dist)))
```

```{r boot_n10_q, echo = FALSE}
  question("מה בערך ההפרש בין ממוצעי ההתפלגויות כשגודל הדגימה הוא 10",
         answer("0.55",  correct=TRUE, message ="נכון מאוד! הייתה הגדלה קלה בהפרש אבל עדיין ההתפלגויות מואד דומות."),
         answer("0.25",  message = "זאת לא התשובה, האם שיניתם את גודל המדגם ל10?"),
         answer("1", message = "זאת לא התשובה, האם שיניתם את גודל המדגם ל10?"),
         answer("1.2",  message = "זאת לא התשובה, האם שיניתם את גודל המדגם ל10?"),
         allow_retry = TRUE
  )
```

```{r boot_n10_q1_q, echo = FALSE}
  question("מה בערך ההפרש בין ממוצעי ההתפלגויות כשגודל הדגימה הוא 10 והמדד המרכזי הוא הרבעון הראשון",
         answer("0.55",   message =" זאת לא התשובה, האם שיניתם את גודל  המדגם ל10? האם שיניתם את הסטטיסטי לאחוזון ה25?"),
         
         answer("0.25", correct=TRUE, message = "מצויין! במקרה זה אנחנו רואים שהבוטסטרפ רועש יותר (שכן הוא חשוף לחלק קטן מאוד מההתפלגות המקורית) אבל עדיין מצליח לשמור על דיוק גבוה!"),
         answer("1", message = "זאת לא התשובה, האם שיניתם את גודל המדגם ל10?האם שיניתם את הסטטיסטי לאחוזון ה25?"),
         answer("1.2",  message = "זאת לא התשובה, האם שיניתם את גודל המדגם ל10?האם שיניתם את הסטטיסטי לאחוזון ה25?"),
         allow_retry = TRUE
  )
```

## Permutation test

### מבוא

מבחן פרמוטציות דומה לבוטסטרפ, אך הוא מאפשר לנו ממש לבצע בדיקת השערות. 
נוכל להשתמש במבחן זה במקרה בו הנחות הסטטיסטיקה הפרמטרית מופרות, וגם אם לא, רק שבמקום להשוות את הסטטיסטי שלנו להתפלגות ידועה (למשל התפלגות t) אנחנו נייצר התפלגות המייצגת את השערת האפס מנתוני המדגם הנוכחי.  
משמעות המונח פרמוטציה הוא ביצוע של תהליך חזרתי, הכולל מספר איטרציות ובכל איטרציה יש ערבוב של הנתונים. במקרה של מבחן פרמוטציות אנחנו נרצה לבצע דווקא דגימה ללא החזרה, כך שכל תצפית במדגם המקורי תחזור על עצמה פעם אחת, אך נדגום את הנתונים כך שגורם התלות עליו נרצה לבצע את המבחן מעורבב בצורה אקראית.  

## מבחן פרמוטציות לשני מדגמים בלתי תלויים
קצת באוויר? זה רעיון מורכב, בואו נפרק אותו עם דוגמה ספציפית.  
בואו נחזור לדוגמה שראינו לגבי שכר. למה דווקא שכר? בגלל שנתוני שכר נהוג למדוד בחציון, שכן הממוצע עשוי להיות מוטה ולא לשקף את האוכלוסיה.   

עכשיו נרצה לבצע בדיקת השערות לגבי השאלה. נוכל לעשות זאת על ידי השוואה של שתי קבוצות. נאסוף מדגם של סטודנטים שלמדו תכנות בתואר וכאלה שלא. השערת האפס היא שאין הבדל בין הקבוצות ואילו ההשערה האלטרנטיבית שאפשר היה לנסח היא שחציון השכר של מי שלמדו תכנות שונה משל אלה שלא.  

עד כה, אמור להיות מוכר, כמו מבחן t. אבל כדי לבצע את המבחן בצורה א-פרמטרית נצטרך בעצם ליצור את הנחת האפס באמצעות פרמוטציות ולהשוות אותה למדגם הנוכחי.  
ועכשיו נצלול אל תוך השערת האפס, מה היא מניחה?  
בגדול היא מניחה שהחלוקה לקבוצות היא אקראית וחסרת משמעות. בעצם אם המשתנה הבלתי תלוי חסר השפעה זה לא משנה מאיזה קבוצה נדגום, אנחנו נקבל אומדנים לאותו החציון.  

איך נעשה את זה?  
ההנחה הזאת בעצם אומרת שאם נאחד את שתי הקבוצות ונדגום מתוכן שתי קבוצות שונות באופן אקראי התוצאה לא אמורה להיות שונה באופן מהותי מתוצאות המדגם המקורי.  

ועכשיו נוכל להקים את השערת האפס לתחיה על ידי ביצוע של לולאה.  


```{r}
# הנתונים נמצאים בטבלה
head(salary_df)

# הסטטיסטי שלנו יהיה הפרש החציונים 
median_diff <- median(salary_df$salary[salary_df$group=="programming"]) - median(salary_df$salary[salary_df$group=="no_programming"])

print(median_diff)

# נצייר את ההתפלגויות 
ggplot(salary_df, aes(x=salary, col=group)) + geom_histogram(fill="white", alpha=0.5, position="identity",bins=50)

```

הנתונים שלנו משקפים מצב בו יש הבדל בין חציוני הקבוצות.  
כלומר, הפרשי החציונים שהתקבלו אמורים להיות לא סבירים תחת השערת האפס.  
נתחיל בלהבין את ההגיון של הערבוב  

```{r}
# השערת האפס בעצם תדגום מחדש את החלוקה לקבוצות
# לכן יעזור לנו לייצר וקטור שמכיל את תוצאות שתי הקבוצות יחד
all_salary_data <- salary_df$salary
# נייצר גם משתנה שמכיל את גודל קבוצת הסטודנטים שלמדו תכנות
groupP_size <- length(salary_df$salary[salary_df$group=="programming"])

# נוכל לערבב את הנתונים באמצעות אותה פונקציה
all_salary_temp <- sample(all_salary_data, replace = FALSE)
# שימו לב שעכשיו נדגום מדגמים באותו גודל ללא החזרה
# לכן ההבדל היחיד יהיה הסדר
# בואו נשווה את ה10 תצפיות הראשונות
# המקור
print(all_salary_data[1:10])
# הוקטור המעורבב
print(all_salary_temp[1:10])

# הן שונות אך באותו גודל
# בואו נוודא
print(length(all_salary_data)==length(all_salary_temp))

# לאחר הערבוב אנחנו כבר לא יודעים מי שייך לאיזה קבוצה
# אז נקצה אותם אקראית


temp_programming <- all_salary_temp[1:groupP_size]
temp_no_programming <- all_salary_temp[(groupP_size+1):nrow(salary_df)]

# יופי יש לנו מדגם מדומה
# נוכל לחשב את הפרש החציונים 
temp_median_diff <- median(temp_programming) - median(temp_no_programming)
print(temp_median_diff)

```
זהו בעצם התהליך של פרמוטציה בודדת. קיבלנו הפרש חציונים קטן מאוד וזה מאוד הגיוני. בעצם ערבבנו את שתי הקבוצות והסיכוי לקבל כזה הפרש באקראי קטן יותר. ההבדל בפרמוטציה אחת יכול להיות קטן מאוד או גדול מאוד לכל כיוון, לכן פרמוטציה אחת לא מספקת לנו מענה. נרצה לדגום מספר גדול של מדגמים אקראים כדי לבנות התפלגות מלאה.  

`תרגיל`  
החציון היא רק דוגמה אחת. אם הייתה לנו השערה לגבי העשירון התחתון? (כלומר שהאחוזון ה10 נופל במקומות שונים בין שתי ההתפלגויות). בצעו את השינויים הדרושים בקוד כדי שהפעם ישמר ההפרש בין מיקום האחוזון ה10 בין שתי הקבוצות.  
רמז - השתמשו בפונקציה quantile()

```{r quantile_2samp_ex, exercise=TRUE, exercise.eval = FALSE }
set.seed(234)
# צרו וקטור
all_salary_data <-
# חשבו את גודל אחת הקבוצות
groupP_size <- 

# ערבבו אותו
all_salary_temp <- sample()
# חלקו לקבוצות
temp_programming <- 
temp_no_programming <- 

# חשבו והדפיסו את ההפרש במיקום האחוזון ה10
temp_quantile_diff <- 

# הדפסה (לא לשנות)
print(as.numeric(round(temp_quantile_diff)))
```

```{r quantile_2samp_ex-solution}
set.seed(234)
# צרו וקטור
all_salary_data <- salary_df$salary
groupP_size <- length(salary_df$salary[salary_df$group=="programming"])

# ערבבו אותו
all_salary_temp <- sample(all_salary_data, replace = FALSE)
# חלקו לקבוצות
temp_programming <- all_salary_temp[1:groupP_size]
temp_no_programming <- all_salary_temp[(groupP_size+1):nrow(salary_df)]

# חשבו והדפיסו את ההפרש במיקום האחוזון ה10
temp_quantile_diff <-  quantile(temp_programming, probs = 0.1) -quantile(temp_no_programming, probs = 0.1)
print(as.numeric(round(temp_quantile_diff)))

```

```{r quantile_2samp_ex-check}
grade_result(pass_if(~identical(.result, 215)),
  
    correct="מצויין! הבנתם איך לשנות את המדד", 
  incorrect = "נסו שוב! רמז - השינוי העיקרי פה יהיה בשלב של חישוב הסטטיסטי?"
)
```

עכשיו שהבנו את העיקרון של חישוב סטטיסטי על סמך חלוקה אקראית לקבוצות נוכל לעבור לחלק של ביצוע לולאת הפרמוטציות. בואו נראה:

```{r}
# נקבע את הפרמטרים   
n_iter <- 10000
# נאכסן את מספר התצפיות בכל קבוצה
groupP_size <- length(salary_df$salary[salary_df$group=="programming"])
# ניצור את הוקטור שישמור את התוצאות
# שימו לב! במקרה זה המטרה היא לדמות את התפלגות האפס
H0_dist <- numeric(n_iter)
# הוקטור לערבוב
all_salary_data <- salary_df$salary
  
# הלולאה 
for (i in 1:n_iter){
  # נערבב את הנתונים
  all_salary_temp <- sample(all_salary_data, replace = FALSE)
  # החצי הראשון יהיה הקבוצה שלמדה תכנות
  temp_programming <- all_salary_temp[1:groupP_size]
  # והחצי השני יהיה קבוצה שלא
  temp_no_programming <- all_salary_temp[(groupP_size+1):nrow(salary_df)]
  # נחשב את הפרש החציונים
  temp_median_diff <- median(temp_programming) - median(temp_no_programming)
  #נאכסן את התוצאה
  H0_dist[i] <- temp_median_diff
} 

# עכשיו אנחנו יכולים לחשב מה הסיכוי לקבל את הפרש חציוני המדגם תחת השערת האפס
median_diff <- median(salary_df$salary[salary_df$group=="programming"]) - median(salary_df$salary[salary_df$group=="no_programming"])

# p-value
# ,נחשב מה הסיכוי לקבל הפרש חציונים כזה קיצוני תחת השערת האפס
# כלומר, כמה תצפיות גדולות יותר היו בהתפלגות האפס?
# ונחלק את כמות התצפיות בגודל ההתפלגות
p <- sum(H0_dist >= median_diff)/length(H0_dist)
print(p)

# קיבלנו 0

# עכשיו נציג את האיור
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 100) +
  geom_vline(xintercept = median_diff, color = "red", linetype = "dashed") +
  annotate("text", x = median_diff, y = 10, label = "Sample Median Difference", color = "red")

hist_plot

```

קיבלנו ערך מאוד מאוד קיצוני ביחס להתפלגות. מה המשמעות של זה?
המשמעות היא שבכל 10000 הפעמים שערבבנו את הנתונים וחילקנו אותם לשתי קבוצות אקראיות לא התקבל הפרש חציונים כל כך קיצוני.
אפשר להסיק מכך שההסתברות לקבל כזאת תוצאה במקרה היא מאוד לא סבירה תחת השערת האפס.

`תרגיל`  
היחידה לשוויון הזדמנויות רצתה להבין האם יכול להיות שיש פערים מגדריים בנתוני השכר שבידינו.
בצעו מבחן פרמוטציות נוסך על הנתונים באמצעות עריכת הקוד שעבדנו איתו קודם. השוו את הפרשי החציונים בין המגדרים להתפלגות האפס והדפיסו את ערך הp שהתקבל .
בקוד שלכם חשבו את הפרש החציונים כההפרש בין גברים לנשים (כלומר החסירו את משכורות הנשים משל הגברים).   
רמז - האם צריך לשנות משהו בלולאה עצמה מלבד השמות של הקבוצות? 

```{r perm_2samp_ex, exercise=TRUE, exercise.eval = FALSE,exercise.reveal_solution = FALSE}
set.seed(234)
n_iter <- 10000
groupF_size <- length(salary_df$salary[salary_df$gender=="Female"])
H0_dist <- numeric(n_iter)
all_salary_data <- salary_df$salary
  
# הלולאה 
for (i in 1:n_iter){
  # נערבב את הנתונים
  all_salary_temp <- sample(all_salary_data, replace = FALSE)
  # החצי הראשון יהיה הקבוצה שלמדה תכנות
  temp_programming <- all_salary_temp[1:groupF_size]
  # והחצי השני יהיה קבוצה שלא
  temp_no_programming <- all_salary_temp[(groupF_size+1):nrow(salary_df)]
  # נחשב את הפרש החציונים
  temp_median_diff <- median(temp_programming) - median(temp_no_programming)
  #נאכסן את התוצאה
  H0_dist[i] <- temp_median_diff
} 

# עכשיו אנחנו יכולים לחשב את הסיכוי של התוצאה האמיתי תחת השערת האפס
median_diff <- 

p <- sum(H0_dist >= median_diff)/length(H0_dist)

#  האיור
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 100) +
  geom_vline(xintercept = median_diff, color = "red", linetype = "dashed") +
  annotate("text", x = median_diff, y = 10, label = "Sample Median Difference", color = "red")

hist_plot
print(round(p,2))

```

```{r perm_2samp_ex-solution}
set.seed(234)
n_iter <- 10000
groupF_size <- length(salary_df$salary[salary_df$gender=="Female"])
H0_dist <- numeric(n_iter)
all_salary_data <- salary_df$salary
  
# הלולאה 
for (i in 1:n_iter){
  # נערבב את הנתונים
  all_salary_temp <- sample(all_salary_data, replace = FALSE)
  # החצי הראשון יהיה הקבוצה שלמדה תכנות
  temp_programming <- all_salary_temp[1:groupF_size]
  # והחצי השני יהיה קבוצה שלא
  temp_no_programming <- all_salary_temp[(groupF_size+1):nrow(salary_df)]
  # נחשב את הפרש החציונים
  temp_median_diff <- median(temp_programming) - median(temp_no_programming)
  #נאכסן את התוצאה
  H0_dist[i] <- temp_median_diff
} 

# עכשיו אנחנו יכולים לחשב את הסיכוי של התוצאה האמיתי תחת השערת האפס
median_diff <- median(salary_df$salary[salary_df$gender=="Male"]) - median(salary_df$salary[salary_df$gender=="Female"])

p <- sum(H0_dist >= median_diff)/length(H0_dist)
print(p)


# עכשיו נציג את האיור
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 100) +
  geom_vline(xintercept = median_diff, color = "red", linetype = "dashed") +
  annotate("text", x = median_diff, y = 10, label = "Sample Median", color = "red")

hist_plot
```

```{r perm_2samp_ex-check}
grade_result(pass_if(~identical(.result, 0.09)),
  
    correct="כל הכבוד! חישבתם נכון!
    קיבלנו ערך של כמעט 10%, כלומר בהתפלגות האפס המדומה נדגמו מדגמים בעלי תוצאה קיצונית כזאת או יותר. לכן תחת רמת בטחון של 95% לא ניתן לדחות את השערת האפס.", 
  incorrect = "נסו שוב! בדקו את ערך ההשוואה, האם עדכנתם אותו?"
)
```

עם שינוי מאוד קטן בקוד יכולנו להשתמש באותה לולאה כדי לדמות את התפלגות האפס של שני מבחנים שונים! כלומר
עם שינוי מאוד קטן בקוד יכולנו להשתמש באותה לולאה כדי לדמות את התפלגות האפס של שני מבחנים שונים (כל עוד שמים לב שגדלי הקבוצות המקוריות עוברות התאמה)! כלומר ברגע שהבנו את העיקרון, נפתחו בפנינו מגוון של אפשרויות. 



## מבחן לשני מדגמים מזווגים

עכשיו כבר יש לנו את העיקרון של ביצוע מבחן פרמוטציות. כל מה שנצטרך לעשות כדי להתאים את התהליך למדגם למבחנים תלויים זה להבין איך לדמות את השערת האפס הפעם.  
ההבדל בהשערת האפס המתאימה למבחן מזווג היא שהשערת האפס לא כוללת בתוכה ערבוב של זהות הזוגות.  
למשל אם נתרגם את הדוגמה המקורית שלנו למבחן מזווג, נוכל לבחון את ההשכר של כל משתתף במדגם לפני ואחרי לימודי התכנות. לכל משתתף בעצם יש שתי תצפיות שתלויות זו בזו. את זהות הנבדקים אנחנו לא נרצה לערבב, שכן גם תחת השערת האפס מתקיימת ההנחה שיש קשר בין תצפיות של אותו הנבדק, לכן הן תלויות.  אלא תחת השערת האפס אין משמעות לסדר - מה הייתה המדידה שלפני ומה הייתה המדידה שאחרי המניפולציה.

```{r paired_perm_q, echo = FALSE}
question("איך אתם מציעים להתאים את התהליך למבחן זה?",
         answer("נרצה לערבב רק את הסדר של התצפיות אחרי לימודי התכנות (כך שהערכים של נבדקים שונים אחרי הלימוד יעורבבו באקראי)",  message ="לא נכון, ערבוב זה ינתק את הזיווג בין התצפיות ואותו לא נרצה לשנות. אבל, זה סוג של ערבוב שיכול להיות רלוונטי למבחן קורלציה. ראו הסבר בהמשך. "),
         answer("עכשיו בכל פרמוטציה נרצה לדגום במקרה חלק מהנבדקים ולהפוך את סדר התצפיות שלהם (השכר שהרוויחו לפני לימודי התכנות יוחלף עם השכר שהרוויחו אחרי)", correct = TRUE, message = " "),
         answer("בכל פרמוטציה נרצה לאחד את שתי הקבוצות, לערבב את הנתונים ולחלק מחדש לקבוצת הלפני והאחרי בצורה אקראית", message = "לא נכון. זאת האופציה שמתאימה לשני מדגמים בלתי תלויים"),
         answer("בכל פרמוטציה נוסיף את ממוצע הקבוצה לחצי מהתצפיות המזווגת", message = "לא נכון"),
         allow_retry = TRUE
)
```

אחרי שהבנו מה צריך לעשות, בואו נראה איך. 
נתחיל מדוגמה מאוד פשוטה כדי להבין. 

```{r}
set.seed(156)
# יש לנו פה קבוצה שיש בה ערכים שונים לפני המניפולציה
before <- c(100, 7, 55, 208, 19)
# ועכשיו קבוצה שניה בה הערכים לאחר המניפולציה
after <- c(122, 17, 65, 230, 42)
# כל אחד מערכי הקבוצה עלה
# במבחן כזה בעצם נרצה להשוות את ממוצע ההפרשים ל0

diff <- after-before
print(paste("Mean Diffrence: ", mean(diff)))

# עכשיו שימו לב!
# נרצה לדגום באקראי אך בלי לנתק את הקשר שבין התצפיות

# דרך אחת לעשות זאת היא על ידי שימוש בלולאה שמבצעת את הערבוב לכל נבדק 
# ניצור וקטורים שיאכסנו את הנתונים המעורבבים
temp_before <- numeric(length(before))
temp_after <- numeric(length(after))
# נעבור על הנבדקים אחד אחד
for (s in 1:length(before)){
  sub_data_temp <- c(before[s], after[s])
  # נערבב את הנתונים
  sub_salary_temp <- sample(sub_data_temp, replace = FALSE)
  # התוצאה תהיה שבחלק מהמקרים תוצאות הנבדק ישארו זהות ובחלק הסדר יתהפך
  # נכניס את הערכים לוקטורים
  temp_before[s] <- sub_salary_temp[1]
  temp_after[s] <- sub_salary_temp[2]
} 

# נסתכל על ההבדל
print(paste("Original Before Vector:", paste(before, collapse = " "), "| Shuffled: ",  paste(temp_before, collapse = " ")))


# חלק מהתצפיות הוחלפו בתצפית שאחרי המניפולציה
# נתבונן בהשפעה על ההפרשים
print(paste("Original Difference Vector:", paste(after-before, collapse = " "), "| Shuffled: ", paste(temp_after-temp_before, collapse = " ")))

# ואיך זה השפיע על ממוצע ההפרשים?
print(paste0("Original Difference Mean: ", mean(after-before), ", Shuffled: ", mean(temp_after-temp_before)))

```

עכשיו יש לנו את תהליך הערבוב. כל מה שנשאר זה להוסיף את הלולאה.  

`תרגיל`  
בתיבת הקוד קיים לכם הקוד שהודגם למעלה. הוסיפו את הלולאה החיצונית והריצו אותה (כמספר הפרמוטציות שמוגדרות בתיבה).  
לסיום, חשבו מה הסיכוי שיתקבלו הפרשי המדגם המקורי תחת התפלגות האפס המדומה.  
תזכורת: השערת החוקר היא שלימודי תכנות מעלים את תוחלת השכר.
משהו לא מצליח ולא הבנתם מה? יכול להיות שיהיה יותר נוח לכם לעבוד על התרגיל בRstudio.

```{r perm_dep_loop_ex, exercise=TRUE, exercise.eval = FALSE }
set.seed(156)
# הנתונים המקוריים 
before <- c(100, 7, 55, 208, 19)
after <- c(122, 17, 65, 230, 42)
diff <- after-before

# הגדרת כמות הפרמוטציות
n_iter <- 1000

# ניצור וקטור שיכיל את התפלגות האפס
H0_dist <- numeric(n_iter)

# הוסיפו את הלולאה כאן

# הלולאה הפנימית
temp_before <- numeric(length(before))
temp_after <- numeric(length(after))
# נעבור על הנבדקים אחד אחד
for (s in 1:length(before)){
  sub_data_temp <- c(before[s], after[s])
  # נערבב את הנתונים
  sub_salary_temp <- sample(sub_data_temp, replace = FALSE)
  # התוצאה תהיה שבחצי מהמקרים תוצאות הנבדק ישארו זהות ובחצי הסדר יתהפך
  # נכניס את הערכים לוקטורים
  temp_before[s] <- sub_salary_temp[1]
  temp_after[s] <- sub_salary_temp[2]
} 
# בסיום הריצה של הלולאה הפנימית צריך לחשב את הסטטיסטי של המדגם המדומה
# במקרה זה נחשב את ממוצע ההפרשים בין הוקטורים המדומים ונאכסן בוקטור

# סגרו את הלולאה כאן

# חשבו את הסיכוי לקבל את המדגם המקורי תחת השערת האפס
p <- 


# עכשיו נציג את האיור
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 10) +
  geom_vline(xintercept = mean(diff), color = "red", linetype = "dashed") +
  annotate("text", x = mean(diff), y = 10, label = "Sample mean", color = "red")

hist_plot

# הדפסה
print(round(p,2))

```

```{r perm_dep_loop_ex-solution}
set.seed(156)
# הנתונים המקוריים 
before <- c(100, 7, 55, 208, 19)
after <- c(122, 17, 65, 230, 42)
diff <- after-before

# הגדרת כמות הפרמוטציות
n_iter <- 1000

# ניצור וקטור שיכיל את התפלגות האפס
H0_dist <- numeric(n_iter)

# הוסיפו את הלולאה כאן
for(i in 1:n_iter){
# הלולאה הפנימית
temp_before <- numeric(length(before))
temp_after <- numeric(length(after))
# נעבור על הנבדקים אחד אחד
for (s in 1:length(before)){
  sub_data_temp <- c(before[s], after[s])
  # נערבב את הנתונים
  sub_salary_temp <- sample(sub_data_temp, replace = FALSE)
  # התוצאה תהיה שבחצי מהמקרים תוצאות הנבדק ישארו זהות ובחצי הסדר יתהפך
  # נכניס את הערכים לוקטורים
  temp_before[s] <- sub_salary_temp[1]
  temp_after[s] <- sub_salary_temp[2]
} 
# בסיום הריצה של הלולאה הפנימית צריך לחשב את הסטטיסטי של המדגם המדומה
# במקרה זה נחשב את ממוצע ההפרשים בין הוקטורים המדומים ונאכסן בוקטור
H0_dist[i] <- mean(temp_after-temp_before)
# סגרו את הלולאה כאן
}
# חשבו את הסיכוי לקבל את המדגם המקורי תחת השערת האפס
p <- sum(H0_dist >= mean(diff))/length(H0_dist)


# עכשיו נציג את האיור
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 10) +
  geom_vline(xintercept = mean(diff), color = "red", linetype = "dashed") +
  annotate("text", x = mean(diff), y = 10, label = "Sample mean", color = "red")

hist_plot

# הדפסה
print(round(p,2))
```

```{r perm_dep_loop_ex-check}
grade_result(pass_if(~identical(.result, 0.03)),
  
    correct="כל הכבוד! גם במקרה קיבלנו סיכוי מאוד נמוך למדגם האמיתי תחת השערת האפס. כיוון שהערך נמוך מ0.05, רמת הבטחון, אפשר לדחות את השערת האפס.", 
  incorrect = "נסו שוב! בדקו שאתם שומרים את הסטטיסטי הנכון בלולאה.?"
)
```

### מבחן פרמוטציות עם ערך ייחוס
אפשר לחשוב על המבחן שביצענו פה מזווית אחרת. הסטטיסטי שלנו במבחן המזווג, כדוגמת המבחן הנוכחי, הוא ממוצע ההפרשים. כלומר מלכתחילה אפשר היה לבצע את המבחן על ההפרשים ולא על שתי הקבוצות.  

ביצוע של המבחן באופן הזה משנה מעט את הביצוע שלו ואת הניסוח של השערת האפס באופן קונקרטי, אך לא מהותית. השערת האפס היא עדיין שאין חשיבות לאיזה תצפית הייתה לפני המניפולציה ואיזה אחריה ולכן תחת השערת האפס הכיוון של ההפרש (האם מחסירים את הערך שלפני המניפולציה מהערך שאחריה) לא משנה.  
כלומר, אפשר לנסח את ההשערה גם כך - השערת האפס היא שתוחלת ההפרשים היא אפס. לכן אם נסתכל על הוקטור של ההפרשים, תחת השערת האפס, הם אמורים להתפזר אקראית סביב אפס והסימן (האם הערכים הם חיוביים או שליליים) של ההפרשים הוא אקראי.  
אם נתרגם את הרעיון הזה לקוד, נוכל לבצע את המבחן אחרת, ללא הלולאה הפנימית. 
נשתמש בוקטור האמיתי של ההפרשים ובנוסף אליו נדגום אקראית וקטור בעל אורך זהה שמכיל רק -1 ו1. נכפול את הוקטורים, מה שיגרום לכך שהסימן של חלק מההפרשים יתהפך. 

בואו נראה איך זה נראה:

```{r}
set.seed(156)
# הנתונים המקוריים 
before <- c(100, 7, 55, 208, 19)
after <- c(122, 17, 65, 230, 42)
diff <- after-before

#  כמות הפרמוטציות
n_iter <- 1000

#  וקטור התפלגות האפס
H0_dist <- numeric(n_iter)

# הלולאת הפרמוטציות
for(i in 1:n_iter){
# ניצור העתק של וקטור ההפרשים
temp_diff <- diff
# נדגום מקרית וקטור שמכיל 1 ו-1
# את הדגימה נבצע מתוך וקטור שמכיל רק 1 ו-1
# נדגום כמות ערכים כאורך הוקטור המקורי
# נצטרך דגימה עם החזרה כיוון שאנחנו דוגמים מוקטור שיש בו שני ערכים
temp <- sample(c(-1,1), length(diff), replace = TRUE)
# נכפול בין הוקטורים
temp_diff = temp_diff*temp
# נאכסן את ממוצע ההפרשים
H0_dist[i] <- mean(temp_diff)
}
# נחשב את ההסתברות לקבל את המדגם המקורי תחת השערת האפס
p <- sum(H0_dist >= diff)/length(H0_dist)
p

# עכשיו נציג את התוצאה
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 10) +
  geom_vline(xintercept = mean(diff), color = "red", linetype = "dashed") +
  annotate("text", x = mean(diff), y = 10, label = "Sample mean", color = "red")

hist_plot

```

גם במקרה הזה קיבלנו תוצאה מאוד מאוד דומה, אך לא זהה כיוון שיש רכיב אקראי. בעצם אם תריצו את אותו קוד פעמיים (ללא השורה של set.seed) תקבלו תוצאות קצת אחרות בכל פעם. זאת כיוון שהתהליך של הדגימה יהיה אקראי ולא בהכרח יחזור על עצמו בדיוק. אך מצד שני, כיוון שהנתונים המקוריים נשארים זהים ההבדלים לא אמורים להיות גדולים מאוד.   

```{r n_perm_q, echo = FALSE}
question("הרצתי את אותו מבחן פעמיים ודווקא כן קיבלתי הבדלים גדולים בתוצאות, למה שיקרה דבר כזה?",
         answer("סימן שאין באמת הבדל מובהק",  message ="אם יש לנו אפקט גבולי מאוד יכול להיווצר מצב בו נריץ את המבחן פעמיים ופעם נוכל לדחות את השערת האפס ופעם לא, אך אם השתמשנו בכמות מספקת של פרמוטציות ההתפלגות עצמה וההסתברות של ערך המבחן תחת ההתפלגות לא אמורים להיות שונים מהותית."),
         answer("השתמשתי בדגימה עם החזרה",  message = "זה נכון שדגימה עם החזרה במקרה שאמורים לדגום ללא תוכל לשנות את התוצאות. אבל עדיין התוצאה בהרצות שונות של אותו הקוד אמורות לצאת דומות אם השתמשנו במספיק פרמוטציות."),
         answer("נעשה שינוי של הגרעין הרנדומלי", message = "זה נכון ששינוי של הגרעין ישנה את הערך הסופי שיתקבל, אבל עדיין לא אמורים להיות הבדלים משמעותיים, אם השתמשנו בכמות מספקת של פרמוטציות"),
         answer("לא השתמשתי במספיק פרמוטציות", correct = TRUE, message = "נכון! מבחן פרמוטציות אמין רק כאשר משתמשים במספר מינימלי של פרמוטציות. אם למשל נסתכל על המקרה הקיצוני בו נשתמש בפרמוטציה אחת כל פעם, ונריץ את המבחן פעמיים יש סיכוי שנקבל תוצאות הפוכות לגמרי"),
         allow_retry = TRUE
)
```

השאלה מחדדת לנו את החשיבות של כמות הפרמוטציות. החוזקה של מבחן זה היא שהיא יכולה לייצר את התפלגות האפס יש מאין, אבל ההתפלגות תהיה אמינה רק אם תהיה לנו כמות מינימלית של פרמוטציות. 
עכשיו שהבנו את נושא כמות הפרמוטציות נוכל להשתמש בעיקרון של השוואה לערך ייחוס כדי לבצע גם השוואה של הסטטיסטי של מדגם מסוים לערך ידוע. במקרה של וקטור ההפרשים השוונו לאפס שכן זאת ההשערה המתאימה. 

אבל אפשר להרחיב את האפשריות ולבחון שאלות כמו זאת: במפעל מסוים רצו לבדוק האם המטבעות המיוצרים במפעל הינם מטבעות הוגנים. כלומר, האם הסיכוי לקבל "עץ" שווה לסיכוי לקבל "פלי". במפעל דגמו 30 מטבעות מפס היצור והטילו כל אחד מהם 10 פעמים וחישבו את הסיכוי לקבל "עץ" על פני החזרות. עכשיו נרצה להשוות את המדגם לסיכוי של מטבע הוגן - 0.5.  
ההתאמה היחידה שנצטרך לבצע היא בעצם למצוא את הדרך להפוך את ערך הייחוס ל0 שכן שינוי הסימן בצורה אקראית מבוסס על ערך ייחוס של 0. נוכל לעשות זאת על ידי החסרה של ערך הייחוס מהנתונים עצמם. כלומר על השוואת ההפרש בין כל ערך במדגם לערך היחוס, תחת השערת האפס שאין הבדל.

`תרגיל`  
כתבו את הקוד שיבצע מבחן פרמוטציות ויבדוק האם המטבע הוגן. הנתונים קיימים כבר בסביבת העבודה שלכם בוקטור שנקרא: coin_sample. כל ערך בוקטור מייצג את אחוז הפעמים בהן התקבל עץ על פני 10 הטלות לכל מטבע שנדגם.  


```{r one_samp_perm_ex, exercise=TRUE, exercise.eval = FALSE,exercise.reveal_solution = TRUE}

set.seed(156)
# הנתונים  
print(coin_sample)

# בצעו את ההתאמה כך שערך הייחוס יהיה אפס ולא 0.5
adj_coin_sample <- 

# הגדרת כמות הפרמוטציות
n_iter <- 1000

# ניצור וקטור שיכיל את התפלגות האפס
H0_dist <- numeric(n_iter)

# לולאת הפרמוטציות
for (i in 1:n_iter){
  # מה הם הנתונים שנרצה לערבב?
  # נתוני המדגם הנוכחי
  temp_data <- 
  # דגמו וקטור שיהפוך את הסימן
  temp <- 
  # נכפול בין הוקטורים
  
  # נאכסן את הממוצע 

} 

# חשבו את הסיכוי לקבל את המדגם המקורי תחת השערת האפס
p <- sum(H0_dist >= mean(adj_coin_sample))/length(H0_dist)

# הדפיסו אותו
print(p)

# עכשיו נציג את האיור
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 10) +
  geom_vline(xintercept = mean(adj_coin_sample), color = "red", linetype = "dashed") +
  annotate("text", x = mean(adj_coin_sample), y = 10, label = "Sample mean", color = "red")

hist_plot


# הדפיסו אותו
print(round(p,1))
```

```{r one_samp_perm_ex-solution}
set.seed(156)
# הנתונים  
print(coin_sample)

# בצעו את ההתאמה כך שערך הייחוס יהיה אפס ולא 0.5
adj_coin_sample <- coin_sample -0.5

# הגדרת כמות הפרמוטציות
n_iter <- 1000

# ניצור וקטור שיכיל את התפלגות האפס
H0_dist <- numeric(n_iter)

# לולאת הפרמוטציות
for (i in 1:n_iter){
  # מה הם הנתונים שנרצה לערבב?
  # נתוני המדגם הנוכחי המתוקנים
  temp_data <- adj_coin_sample
  # דגמו וקטור שיהפוך את הסימן
  temp <- sample(c(-1,1), length(adj_coin_sample), replace = TRUE)
  # נכפול בין הוקטורים
  temp_data = temp_data*temp
  # נאכסן את הממוצע 
  H0_dist[i] <- mean(temp_data)
} 

# חשבו את הסיכוי לקבל את המדגם המקורי תחת השערת האפס
p <- sum(H0_dist >= mean(adj_coin_sample))/length(H0_dist)

# עכשיו נציג את האיור
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 10) +
  geom_vline(xintercept = mean(adj_coin_sample), color = "red", linetype = "dashed") +
  annotate("text", x = mean(adj_coin_sample), y = 10, label = "Sample mean", color = "red")

hist_plot
# הצגת ערך p
print(round(p,1))

```

```{r one_samp_perm_ex-check}
grade_result(pass_if(~identical(.result, 0.4)),
  
    correct="מצויין! קיבלנו סיכוי  של 0.4 לקבל מדגם כזה או קיצוני ממנו תחת השערת האפס. כלומר לא נוכל לדחות את השערת האפס שהמטבעות הוגנים.", 
  incorrect = "עוד לא בדיוק הגעתם לערך המדויק. חזרו לדוגמה הקודמת וודאו שביצעתם את הלולאה כמו שצריך."
)
```

## מבחן פרמוטציות לקשר לינארי

המבחן האחרון שנלמד מאפשר לנו לבצע בדיקת מובהקות על קורלציה. כלומר, במקרה זה נוכל לחשב קורלציה בין שני משתנים ולהשוות את הקורלציה להתפלגות המדומה של השערת האפס שנייצר באמצעות פרמוטציות.

אז כמו שאתם בוודאי מנחשים אנחנו צריכים להבין מה היא השערת האפס שלנו במקרה הזה כדי שנוכל לדמות אותה. במובן מסויים השערת האפס במקרה זה היא הפוכה לזאת של מדגמים מזווגים. שכן גורם התלות שנרצה לנתק פה הוא הזיווג בין התצפיות.  
המשמעות של קורלציה היא בעצם ששינוי במשתנה אחד מלווה בשינוי במשתנה שני. השינוי המשותף נובע בעצם מהזיווג בין התצפיות.  
כלומר, במקרה זה השערת האפס טוענת שהצימוד בין התצפיות הינו מקרי, בהינתן שאין קשר לינארי בין שני המשתנים העובדה שקיבלנו ערך גבוה במשתנה אחד לא נותנת לנו שום מידע על הערך שנקבל במשתנה השני.  

הפעם בקוד בכל פרמוטציה אנחנו נשמור על אחד המשתנים (נקרא לו X) כפי שהוא ואת המשתנה השני (Y) נדגום מחדש בכל פרמוטציה, כל שבכל פעם תצפית מסוימת בX תהיה מקושרת לתצפית אחרת בY. אם אכן אין קשר, זה לא משנה איזה תצפית של Y מזווגת לX.  

בואו נראה דוגמה:

```{r}
# נשתמש בדוגמה מאוד פשוטה
x <- c(1, 2, 3, 4, 5)
y <- c(11, 12, 12, 15, 16)

# נחשב את הקורלציה
corr_xy <- cor(x, y)
print(corr_xy)

# קיבלנו קורלציה מאוד גבוהה. 
# אבל יש לנו מעט מאוד תצפיות
# מה הסיכוי למצוא קשר כזה במקרה?

# נבצע את המבחן
#  כמות הפרמוטציות
n_iter <- 10000

#  וקטור התפלגות האפס
H0_dist <- numeric(n_iter)

# לולאת הפרמוטציות
for(i in 1:n_iter){
# ניצור העתק של שני הוקטורים המקוריים
# אחד ישמור על צורתו המקורית
temp_x <- x
# ולשני נשנה את הסדר
temp_y <- sample(y,  replace = FALSE)
# נאכסן את הקורלציה בין שני הוקטורים
H0_dist[i] <- cor(temp_x, temp_y)
}
# נחשב את ההסתברות לקבל את ההקורלציה במדגם המקורי תחת השערת האפס
p <- sum(H0_dist >= corr_xy)/length(H0_dist)
p

# עכשיו נציג את התוצאה
hist_plot<-ggplot(data.frame(H0_dist = H0_dist), aes(x = H0_dist)) + geom_histogram(bins = 15) +
  geom_vline(xintercept = corr_xy, color = "red", linetype = "dashed") +
  annotate("text", x = corr_xy, y = 700, label = "Sample mean", color = "red")

hist_plot


```

מעולה, קיבלנו כאן, כמו בכל המקרים הקודמים, את ההסתברות למצוא קורלציה קיצונית כזאת תחת התפלגות האפס. קיבלנו שהסיכוי הוא נמוך מאוד (מתחת ל0.05). לכן אנחנו יכולים לדחות את השערת האפס שהקורלציה במדגם שווה ל0.  
שמתם לב שיש בהיסטוגרמה חור בדיוק בערך 0? זאת כיוון שמאוד קשה להגיע במקרה לקורלציה ששווה בדיוק 0, לכן חשוב מאוד לדמות את ההתפלגות כדי להבין איזה ערכים קיימים בהתפלגות האפס. במקרה שלנו אפילו קורלציה של 0.5 היא קורלציה מאוד סבירה תחת התפלגות האפס (עקב מאפייני המדגם שלנו).  

## תרגיל מסכם
את התרגיל המסכם נבצע בrstudio.
טענו לסביבת העבודה שלכם את הקובץ שמכיל את נתוני מבחן הstroop, איתם עבדנו גם בשיעור האחרון. 
הקפידו לטעון את הקובץ היעודי לשיעורים אלה ולא את הקובץ המקורי. שכן שהשאלות מניחות שהנתונים שלכם כבר מסוננים ומסוכמים כראוי.   

קודם כל כללו בסקריפט שלכם את השורה הבאה:  
`set.seed(123)`
חשוב מאוד לכלול אותה ולהריץ אותה, אחרת התשובות שתקבלו יכולות להיות שונות מהתשובות שלנו.   
בכל המבחנים שנבצע בתרגיל זה נרצה להשתמש ב10,000 פרמוטציות.
קבעו בראש הקובץ שלכם גם את מספר זה על ידי הרצת השורה:  
`n_iter <- 10000`  
 
 `שאלה 1`  
 נתחיל מבחינה של הדיוק של המשתתפים בניסוי.  השתמשו בעמודה Mean_Accuracy לתרגיל זה.  
 בנו רווח סמך ברמת בטחון של 95% לדיוק הממוצע של הנבדקים באמצעות בוטסטרפ. 

```{r final_q1, echo = FALSE}
question("מהו נכון לגבי רווח הסמך?",
         answer("הרווח הסמך כולל את הסיכוי לקבל תשובה נכונה במקרה (0.5)",  message ="לא נכון, בדקו את הקוד שלכם. "),
         answer("רווח הסמך כולל את הערך 1, כלומר כמות הטעויות במדגם הייתה זניחה",  message = "הרווח האמנם קרוב מאוד לשם אבל לא כולל את הערך 1. בדקו את הקוד שלכם."),
         answer("רווח הסמך לא כולל בתוכו את הסיכוי לקבל תשובה נכונה במקרה (0.5) ולא את הערך 1 ", correct=TRUE, message = "נכון מאוד! קיבלנו ערך גבוה שלא כולל את שני הערכים הללו."),
         answer("הערך שקיבלנו שכולל בתוכו גם את הסיכוי לקבל תשובה נכונה במקרה (0.5) וגם את הערך 1.",  message = " לא נכון, קיבלנו ערך צר מאוד והערך המתואר כאן רחב."),
         allow_retry = TRUE
)
```

`שאלה 2`  
אחד החוקרים חשד שיש אפקט סדר במדגם, כך שככל שמספר הנבדק גבוה יותר כך הדיוק גבוה יותר. בחנו את ההשערה שקיימת קורלציה בין מספר הנבדק לרמת הדיוק באמצעות מבחן הפרמוטציות המתאים.

```{r final_q2, echo = FALSE}
question("בכמה פרמוטציות התקבל ערך  גבוה מהקורלציה המקורית ?",
         answer("100-200",  message ="לא נכון, בדקו את הקוד שלכם. "),
         answer("200-1000",  message = "זאת לא התשובה. בדקו את הקוד שלכם"),
         answer("1000-2000", correct=TRUE, message = "נכון מאוד!"),
         answer("מעל 2000",  message = " לא נכון, בדקו את הקוד שלכם."),
         allow_retry = TRUE
)
```

```{r final_q2_2, echo = FALSE}
question("האם אפשר לדחות את השערת האפס?",
         answer("לא",  correct=TRUE, message ="נכון, ברמת בטחון של 95% לא ניתן לדחות את השערת האפס שהקורלציה שווה ל0."),
         answer("כן",  message = "לא נכון, חשבו את ערך הפי, הערך שמתקבל יבהיר לכם האם ניתן לדחות את השערת האפס."),
         answer("לא ברור", message = "כדי לענות על שאלה זאת חשבו את ערך הפי, על ידי חלוקה של התשובה הקודמת במספר האיטרציות. האם הסיכוי לקבל קורלציה כזאת תחת השערת האפס קטן מ5%?"),
         allow_retry = TRUE
)
```

`שאלה 3`   
ועכשיו לאירוע המרכזי - אפקט הסטרופ.   

אנחנו נרצה לשחזר את אחד המבחנים שביצענו בשיעור הקודם, עם אותם נתונים בהם השתמשתם בשיעור הקודם.  
`שימו לב` במעבר לשאלה זאת טענו את הקובץ המסונן שקיבלתם בשיעור הקודם.   

בצעו את מבחן הפרמוטצית המתאים לבחינת אפקט הסטרופ, על ידי השוואה בין זמני התגובה בתנאי התואם לתנאי הלא תואם.  
חשבו היטב, איזה סוג של מבחן מתאים פה? האם הדגימות הן תלויות או בלתי תלויות?

```{r final_q3_1, echo = FALSE}
question("מה נכון לגבי ממוצע התפלגות האפס ?",
         answer(" הוא בין 100-150"),
         answer("הוא בין -10 ל-50"),
         answer("הוא בין 1 ל10"),
         answer("הוא בין -0.5 ל0.5", correct=TRUE),
         allow_retry = TRUE,
             
  correct="מצויין! ", 
  incorrect = "וודאו שהשתמשתם במבחן הנכון ומאפייני הערבוב הנכונים ונסו להריץ את הקוד מההתחלה"
)
```


```{r final_q3_2, echo = FALSE}

question_text(
  "בכמה פרמוטציות התקבל ממוצע הפרשים גבוה מהערך שהתקבל במדגם?",
  answer("0", correct = TRUE),
  allow_retry = TRUE,
    
  correct="נכון מאוד! לא התקבל ערך כזה קיצוני באף פרמוטציה.", 
  incorrect = "וודאו שהשתמשתם בפרמטרים הנכונים ונסו שוב."
)

```


```{r submit_final, echo = FALSE}
  question_text(
    "Please enter the code here",
    incorrect = "Excercise was submitted!",
    correct = "Excercise was submitted!",
    answer(text = "asd",message="DFGDF"),
    answer(text = "",correct = TRUE),
    rows = 10,
    trim = FALSE, allow_retry = TRUE
  )
```

## משוב 

בחלק זה נבקש את המשוב שלכם על הלומדה. אנא ענו בכנות וביסודיות, על מנת שנוכל להשתפר. התשובות ישמרו בצורה אנונימית ולא ישפיעו על בדיקת התרגיל עצמה.  
שימו לב: ברוב השאלות אין אפשרות לשנות את התגובה לאחר לחיצה על כפתור ההגשה.

```{r survey_q1, echo = FALSE}
question("מה הייתה רמת הקושי של הלומדה עבורך? יש להתייחס לכמה הבנת את החומר ולרמת הקושי של התרגול עבורך. ",
         type="single",
         answer("קלה"        ,correct=TRUE,  message = "תגובתך: קלה"),
         answer("בינונית"    ,correct=TRUE,  message = "תגובתך: בינונית"),
         answer("מאתגרת"     ,correct=TRUE,  message = "תגובתך: מאתגרת"),
         answer("קשה"        ,correct=TRUE,  message = "תגובתך: קשה"),
         answer("קשה מאוד"   ,correct=TRUE,  message = "תגובתך: קשה מאוד"),
         correct = "",
         incorrect = "",
         allow_retry = TRUE
)
```

```{r survey_q2, echo = FALSE}
question("עד כמה החומר הנלמד ביחידה הועבר בצורה ברורה לדעתך?",
         type="single",
         answer("במידה רבה"      , correct=TRUE,  message = "תגובתך: במידה רבה"),
         answer("במידה סבירה" ,    correct=TRUE,  message = "תגובתך: במידה סבירה"),
         answer("באופן חלקי"  ,    correct=TRUE,  message = "תגובתך: באופן חלקי"),
         answer("במידה מעטה"  ,correct=TRUE,  message = "תגובתך: במידה מעטה"),
         answer("במידה מעטה מאוד",correct=TRUE,  message = "תגובתך: במידה מעטה מאוד"),
         correct = "",
         incorrect = "",
         allow_retry = TRUE)
```

```{r survey_q3, echo = FALSE}
question("כמה זמן לקח לך לפתור את הלומדה בערך?",
         type="single",
         answer("פחות משעה"      , correct=TRUE,  message = "תגובתך: פחות משעה"),
         answer("שעה" ,    correct=TRUE,  message = "תגובתך: שעה"),
         answer("שעתיים"  ,    correct=TRUE,  message = "תגובתך: שעתיים "),
         answer("שלוש שעות"  ,correct=TRUE,  message = "תגובתך:  שלוש שעות"),
         answer("ארבע שעות ומעלה",correct=TRUE,  message = "תגובתך:  ארבע שעות ומעלה "),
         correct = "",
         incorrect = "",
         allow_retry = TRUE)
```

```{r survey_q4, echo = FALSE}
question(" אילו נושאים בלומדה היו קשים במיוחד עבורך?",type="learnr_checkbox",
         answer("המבוא", correct=TRUE),
         answer("בוטסטראפ", correct=TRUE),
         answer("כל מבחני הפרמוטציות", correct=TRUE),
         answer("מבחן פרמוטציות לשני מדגמים", correct=TRUE),
         answer("מבחן פרמוטציות למדגמים תלויים", correct=TRUE),
         answer(" מבחן פרמוטציות עם ערך ייחוס", correct=TRUE),
         answer("מבחן פרמוטציות לקשר לינארי", correct=TRUE),
         answer("לא היה נושא קשה במיוחד", correct=TRUE),
         correct = "תשובתך התקבלה. תודה על הפירוט",
         try_again = "תשובתך התקבלה. תודה על הפירוט",
         incorrect = "תשובתך התקבלה. תודה על הפירוט",
         allow_retry = TRUE
)
```

```{r survey_q5, echo = FALSE}
  question_text(
    " מצאת טעות? ספר/י לנו עליה (יש להקפיד ולציין את שם הפרק)",
    incorrect = "תשובתך התקבלה!",
    correct = "תשובתך התקבלה!",
    answer(text = "asd",message="DFGDF"),
    answer(text = "",correct = TRUE),
    rows = 10,
    trim = FALSE
  )
```

```{r survey_q6, echo = FALSE}
  question_text(
    "יש לך עוד משהו לספר לנו? נשמח לשמוע משוב מפורט, הצעות כלליות או ספציפיות לפרק מסוים לגבי יחידה זאת.",
    incorrect = "תשובתך התקבלה",
    correct = "תשובתך התקבלה",
    answer(text = "asd",message="DFGDF"),
    answer(text = "",correct = TRUE),
    rows = 10,
    trim = FALSE
  )
```

## הגשת התרגיל
  סיימת? מעולה! עכשיו הגיע הזמן להגיש את התרגיל.  
  יש ללחוץ על הכפתור:  Generate  
  להעתיק את הטקסט שמופיע בחלון למטה ולהגישו במודל  
  בהצלחה!

```{r context="server"}
learnrhash::encoder_logic()
```

```{r encode, echo=FALSE}
learnrhash::encoder_ui()
```



הדביקו את קוד הhash בתוך הגרשיים בפונקצייה הבאה כדי לוודא שעניתם על כל השאלות והתרגילים בלומדה.

```{r hash_check,  exercise = TRUE, exercise.eval = FALSE}

check_hash_code("")

```
